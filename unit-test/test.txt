

1、单连接传输包大小测试：（以\r\n结尾的的内部协议作为测试协议）

（1）无异步队列，直接回调的情况

	包大小分别为128，512， 1K, 4K, 8K, 16K, 32K, 64K
观测点：
	1)CNET是否支持此大小包的传输；
	2)socket缓存区是否有数据积压；
	3)此时对应的网络流量是多少，并根据网络流量的大小计算得出每秒处理的数据流量；

结论：
	1)CNET支持包大小的动态扩展, 经测试包大小128字节-1M都可以正常解析出来。
	2)
	
每包大小： 网络流量：		
   4：2.770M/s
  16：3.360M/s
  64：5.545M/s
 128：8.520M/s                       
 512: 23M/s
  1K: 37M/s
  4K: 71M/s
 16K: 75M/s
 64k: 68M/s
256K: 55M/s
  1M: 27M/s
  4M: 9.8M/s

（2）中间加上异步队列的睇情况

  加上异步队列的情况：
  
 2） 业务线程增加为4个，效果并不明显。后续测试证明，增加业务线程的处理数，对增大网络流量几乎没有影响。
 3） 原先的packet经过一层BasePacket的封装，去掉这层封装，仍然不能解决这个问题。
 
 
    4：2.770M/s ---> 1.5MB
  16：3.360M/s  ---> 2.1MB
  64：5.545M/s  ---> 3.57MB
 128：8.520M/s  ---> 4.0MB                      
 512: 23M/s    ---> 14MB
  1K: 37M/s    ---> 26MB
  4K: 71M/s    ---> 55MB
 16K: 75M/s
 64k: 68M/s
256K: 55M/s
  1M: 27M/s
  4M: 9.8M/s
  
  将线程环境中的sem_post和 sem_wait去掉后，性能惊人！ 达到了152M， 比单线程的还要多1倍！  2014-10-15
 15   2  82   0   0   1|   0     0 | 152M  152M|   0     0 |1018   222k
 15   2  82   0   0   1|   0     0 | 152M  152M|   0     0 |1017   222k
 15   2  82   0   0   1|   0     0 | 152M  152M|   0     0 |1022   221k
 15   2  82   0   0   1|   0   320k| 152M  152M|   0     0 |1030   220k
 15   2  82   0   0   0|   0     0 | 152M  152M|   0     0 |1018   221k
 15   2  82   0   0   1|   0     0 | 152M  152M|   0     0 |1032   221k
 15   2  81   1   0   1|   0  1784k| 152M  152M|   0     0 |1176   222k
  

2、高并发测试（808协议），每包大小默认为1024字节；
	测试并发量别分为1K，10K, 50K, 100K, 200K
观测点：
	1)CNET 是否运行正常（成功连接数是否与发起连接数相同）
	2)socket缓冲区是否有数据积压
	3)对应的处理的网络流量是多少。


3、UDP测试
每个包4个字节时：1M/s-3M/s, 没有一个平滑的曲线
每个包16个字节时：1.5M/s
每个包64个字节时：3M -12M来回跳动，不稳定
每个包128个字节时：
每个包1K个字节时：27M -58M - 26M- 23跳动
每个包4K个字节时：63M
每个包16K个字节时：89M
每个包64K个字节时：108M
